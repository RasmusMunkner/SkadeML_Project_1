library(mlr3)
library(mvtnorm)
library(mlr3learners )
library(mlr3tuning)
library(mlr3mbo)
library(glmnet)
library(xgboost)
library(ranger)
library(mgcv)
library(mlr3extralearners)
#Here data is freq_df, generated by "ML_datasets_Albert.R"

#Model 1, exposure as a feature.

#We want to use binary classification on the following subset.

df_mod1 <- freq_df %>%
  select(-ObsFreq) %>%
    mutate(ClaimInd = as.factor(ClaimInd))

task_mod1 <- as_task_classif(df_mod1, target = "ClaimInd")

#Read in the data for the frequency model, filter out ObsFreq and convert to a MLR3 task.
source("Rasmus_Funktioner.R") #For the ReadData-function
task_mod1 <- ReadData("freq_df") %>% 
  dplyr::select(-ObsFreq) %>%
  as_task_classif(target = "ClaimInd")

#It would be interesting to also tune over the number of trees we use for the model. I have the feeling that 50 are slightly few.
#Also, mtry.ratio ~ 1 is probably much too large. We can most likely get better hyperparameters in fewer evals if we set it down to ~0.5 or lower.
my_ranger_learner = lrn("classif.ranger",
                        mtry.ratio = to_tune(0.1,1),
                        min.node.size = to_tune(1, 50),
                        num.trees = 50,
                        predict_type= "prob")

#For a final model, we should most likely set n_evals >> 10 or instead use a 'Clock_time' terminator.
instance = tune(
  method = tnr("random_search"), ### tuning method
  task = task_mod1,
  learner = my_ranger_learner,
  resampling = rsmp("cv", folds = 5), #### resampling method: 5-fold cross validation
  measures = msr("classif.logloss"), #### Log Loss
  terminator = trm("evals", n_evals = 10) #### terminator
)

#### define tuned ranger learner and train on training data

ranger_tuned = lrn("classif.ranger",
                   predict_type= "prob") 
ranger_tuned$param_set$values = instance$result_learner_param_vals
ranger_tuned$train(task_mod1)

df_mod1<- df_mod1 %>%
  mutate("pred. freq. mod1" = ranger_tuned$predict_newdata(df_mod1)$prob[,2])

#Model 2, multiply with exposure after modelling

df_mod2 <- freq_df %>%
  select(-c(ObsFreq,Exposure)) %>%
  mutate(ClaimInd = as.factor(ClaimInd))%>%
  mutate(BonusMalus = as.numeric(BonusMalus))%>%
  mutate(DrivAge = as.numeric(DrivAge))

task_mod2 <- as_task_classif(df_mod2, target = "ClaimInd")

task_mod2 <- ReadData("freq_df") %>% 
  dplyr::select(-Exposure, -ObsFreq) %>% 
  as_task_classif(target = "ClaimInd")

my_ranger_learner2 = lrn("classif.ranger",
                        mtry.ratio = to_tune(0.1,1),
                        min.node.size = to_tune(1, 50),
                        num.trees = 50,
                        predict_type= "prob")

instance2 = tune(
  method = tnr("random_search"), ### tuning method
  task = task_mod2,
  learner = my_ranger_learner2,
  resampling = rsmp("cv", folds = 5), #### resampling method: 5-fold cross validation
  measures = msr("classif.logloss"), #### Log Loss
  terminator = trm("evals", n_evals = 10) #### terminator
)

#### define tuned ranger learner and train on training data

ranger_tuned2 = lrn("classif.ranger",
                   predict_type= "prob") 
ranger_tuned2$param_set$values = instance2$result_learner_param_vals
ranger_tuned2$train(task_mod2)

df_mod2 <- df_mod2 %>%
  mutate("pred. freq." = ranger_tuned2$predict_newdata(df_mod2)$prob[,2])


<<<<<<< HEAD
results <- ReadData("freq_df") %>%
              add_column(Pred_freq_1 = ranger_tuned$predict_newdata(.)$prob[,2]) %>%
              add_column(Pred_freq_2 = ranger_tuned2$predict_newdata(.)$prob[,2]) %>% 
  select(ClaimInd, Pred_freq_1, Pred_freq_2)
=======

final_df <- freq_df %>%
              mutate(Pred_freq_1 = df_mod1$`pred. freq. mod1`)%>%
              mutate(Pred_freq_2 = df_mod2$`pred. freq.`*freq_df$Exposure)
>>>>>>> 58b42a4cbd9d569a7b008d0bb9fd939402ba44dc
